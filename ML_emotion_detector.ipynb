{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING------\n",
      "7215: happy imgs\n",
      "4830: sad imgs\n",
      "4097: fear imgs\n",
      "3171: surprise imgs\n",
      "4965: neutral imgs\n",
      "3995: angry imgs\n",
      "436: disgust imgs\n",
      "TEST------\n",
      "1774: happy imgs\n",
      "1247: sad imgs\n",
      "1024: fear imgs\n",
      "831: surprise imgs\n",
      "1233: neutral imgs\n",
      "958: angry imgs\n",
      "111: disgust imgs\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAINING------\")\n",
    "for emotion in os.listdir('train/'):\n",
    "    print(str(len(os.listdir('train/' + emotion))) + ': ' + emotion + ' imgs')\n",
    "\n",
    "print(\"TEST------\")\n",
    "for emotion in os.listdir('test/'):\n",
    "    print(str(len(os.listdir('test/' + emotion))) + ': ' + emotion + ' imgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Set image and batch size\n",
    "image_size = (224,224)\n",
    "batch_size = 100\n",
    "\n",
    "# Define the directories for training and testing data\n",
    "train_data = 'train/'\n",
    "test_data = 'test/'\n",
    "\n",
    "# Create the image generator for normilization\n",
    "train_data_gen = ImageDataGenerator(horizontal_flip=True)\n",
    "test_data_gen = ImageDataGenerator(horizontal_flip=True)\n",
    "\n",
    "# Generate the batches of training and test data\n",
    "train_generator = train_data_gen.flow_from_directory(\n",
    "    train_data,\n",
    "    target_size = image_size,\n",
    "    batch_size = batch_size,\n",
    "    color_mode = 'grayscale',\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_data_gen.flow_from_directory(\n",
    "    test_data,\n",
    "    target_size = image_size,\n",
    "    batch_size = batch_size,\n",
    "    color_mode = 'grayscale',\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 111, 111, 32)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 54, 54, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 26, 26, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 86528)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               11075712  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11168513 (42.60 MB)\n",
      "Trainable params: 11168513 (42.60 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224,224, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "287/287 [==============================] - 4229s 15s/step - loss: 3.2712 - accuracy: 0.8492 - val_loss: 0.4155 - val_accuracy: 0.8571\n",
      "Epoch 2/10\n",
      "287/287 [==============================] - 4554s 16s/step - loss: 0.4153 - accuracy: 0.8571 - val_loss: 0.4174 - val_accuracy: 0.8571\n",
      "Epoch 3/10\n",
      "287/287 [==============================] - 4214s 15s/step - loss: 0.4145 - accuracy: 0.8571 - val_loss: 0.4130 - val_accuracy: 0.8571\n",
      "Epoch 4/10\n",
      "287/287 [==============================] - 3813s 13s/step - loss: 0.4133 - accuracy: 0.8571 - val_loss: 0.4145 - val_accuracy: 0.8571\n",
      "Epoch 5/10\n",
      "287/287 [==============================] - 3874s 13s/step - loss: 0.4128 - accuracy: 0.8571 - val_loss: 0.4115 - val_accuracy: 0.8571\n",
      "Epoch 6/10\n",
      "287/287 [==============================] - 3862s 13s/step - loss: 0.4119 - accuracy: 0.8571 - val_loss: 0.4109 - val_accuracy: 0.8571\n",
      "Epoch 7/10\n",
      "287/287 [==============================] - 3896s 14s/step - loss: 0.4111 - accuracy: 0.8571 - val_loss: 0.4111 - val_accuracy: 0.8571\n",
      "Epoch 8/10\n",
      "287/287 [==============================] - 3747s 13s/step - loss: 0.4106 - accuracy: 0.8571 - val_loss: 0.4103 - val_accuracy: 0.8571\n",
      "Epoch 9/10\n",
      "287/287 [==============================] - 3835s 13s/step - loss: 0.4103 - accuracy: 0.8571 - val_loss: 0.4102 - val_accuracy: 0.8571\n",
      "Epoch 10/10\n",
      "287/287 [==============================] - 3842s 13s/step - loss: 0.4102 - accuracy: 0.8571 - val_loss: 0.4102 - val_accuracy: 0.8571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x143ab0a10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_generator,\n",
    "          steps_per_epoch=train_generator.samples // batch_size,\n",
    "          epochs=10,\n",
    "          validation_data=test_generator,\n",
    "          validation_steps=test_generator.samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 255s 4s/step - loss: 0.4102 - accuracy: 0.8571\n",
      "Test accuracy: 0.857143223285675\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_generator, steps=test_generator.samples // batch_size)\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('output/emotion_detection.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 417ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the name of the last convolutional layer\n",
    "last_conv_layer_name = 'conv2d_2'\n",
    "\n",
    "# Load a sample image from your test dataset\n",
    "sample_image_path = 'test/angry/PrivateTest_88305.jpg'\n",
    "img = image.load_img(sample_image_path, target_size=(224, 224), color_mode='grayscale')\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# Define a function to generate CAM using OpenCV\n",
    "def generate_cam(model, last_conv_layer_name, image_path, target_size=(224, 224)):\n",
    "    # Load the image\n",
    "    img = image.load_img(image_path, target_size=target_size, color_mode='grayscale')\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    # Extract the last convolutional layer\n",
    "    last_conv_layer = model.get_layer(last_conv_layer_name)\n",
    "    \n",
    "    # Create a new model with the last convolutional layer as output\n",
    "    cam_model = Model(inputs=model.input, outputs=last_conv_layer.output)\n",
    "    \n",
    "    # Get the weights of the output layer\n",
    "    output_weights = model.layers[-1].get_weights()[0]\n",
    "    \n",
    "    # Compute the feature maps\n",
    "    features = cam_model.predict(img_array)\n",
    "    \n",
    "    # Calculate the class activation map\n",
    "    cam = np.matmul(features, output_weights)\n",
    "    cam = np.sum(cam, axis=-1)\n",
    "    \n",
    "    # Normalize CAM\n",
    "    cam /= np.max(cam)\n",
    "    \n",
    "    # Resize CAM to the size of the input image\n",
    "    cam = cv2.resize(cam[0], target_size)\n",
    "    \n",
    "    # Convert CAM to heatmap\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
    "    \n",
    "    # Convert grayscale image to BGR\n",
    "    img_bgr = cv2.cvtColor(np.uint8(img_array[0]), cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # Overlay the heatmap on the original image\n",
    "    cam_overlay = cv2.addWeighted(heatmap, 0.5, img_bgr, 0.5, 0)\n",
    "    \n",
    "    return cam_overlay\n",
    "\n",
    "\n",
    "\n",
    "# Generate CAM using OpenCV\n",
    "cam_overlay_cv2 = generate_cam(model, last_conv_layer_name, sample_image_path)\n",
    "\n",
    "\n",
    "# Generate CAM using OpenCV\n",
    "cam_overlay_cv2 = generate_cam(model, last_conv_layer_name, sample_image_path)\n",
    "\n",
    "cv2.imwrite('output/cam_overlay_img2.jpg', cam_overlay_cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 669ms/step\n",
      "Predicted Emotion: happy\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('output/emotion_detection.h5')\n",
    "\n",
    "# Define the target size for resizing the images\n",
    "target_size = (224, 224)\n",
    "\n",
    "# Define a function to preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "   # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Resize the image to the target size\n",
    "    resized_image = cv2.resize(gray_image, target_size)\n",
    "    # Normalize the pixel values to be in the range [0, 1]\n",
    "    normalized_image = resized_image / 255.0\n",
    "    # Expand the dimensions of the image to match the input shape expected by the model\n",
    "    expanded_image = np.expand_dims(normalized_image, axis=-1)\n",
    "    # Return the preprocessed image\n",
    "    return expanded_image\n",
    "\n",
    "# Define a function to predict emotion from an image\n",
    "def predict_emotion(image_path):\n",
    "    # Preprocess the image\n",
    "    preprocessed_image = preprocess_image(image_path)\n",
    "    # Make prediction\n",
    "    predictions = model.predict(np.expand_dims(preprocessed_image, axis=0))\n",
    "    # Get the predicted emotion class\n",
    "    predicted_class = np.argmax(predictions)\n",
    "    # Map the predicted class to the corresponding emotion label\n",
    "    emotion_labels = ['happy', 'disgust', 'fear', 'angry', 'sad', 'surprised', 'neutral']\n",
    "    predicted_emotion = emotion_labels[predicted_class]\n",
    "    return predicted_emotion\n",
    "\n",
    "# Test the model on an example image\n",
    "image_path = 'test/fear/PrivateTest_134207.jpg'\n",
    "predicted_emotion = predict_emotion(image_path)\n",
    "print('Predicted Emotion:', predicted_emotion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 449s 6s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.13      1.00      0.24       958\n",
      "     disgust       0.00      0.00      0.00       111\n",
      "        fear       0.00      0.00      0.00      1024\n",
      "       happy       0.00      0.00      0.00      1774\n",
      "     neutral       0.00      0.00      0.00      1233\n",
      "         sad       0.00      0.00      0.00      1247\n",
      "    surprise       0.00      0.00      0.00       831\n",
      "\n",
      "    accuracy                           0.13      7178\n",
      "   macro avg       0.02      0.14      0.03      7178\n",
      "weighted avg       0.02      0.13      0.03      7178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate predictions for the test data\n",
    "y_pred = model.predict(test_generator)\n",
    "\n",
    "# Convert the predicted probabilities to class labels\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Get the true class labels from the test data generator\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Compute precision, recall, and F1-score\n",
    "report = classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys())\n",
    "\n",
    "# Print the classification report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
